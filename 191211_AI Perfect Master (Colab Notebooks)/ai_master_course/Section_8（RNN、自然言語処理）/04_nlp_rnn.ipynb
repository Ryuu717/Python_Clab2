{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"colab":{"name":"04_nlp_rnn.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"C2FDsgdXz7Ev"},"source":["# RNNによる自然言語処理\n","RNNを使って、文書の自動作成を行います。  \n","今回は、宮沢賢治の「銀河鉄道の夜」を学習データに使い、賢治風の文章を自動生成します。  \n","文章における文字の並びを時系列データと捉えて、次の文字を予測するようにRNNを訓練します。  \n","シンプルなRNN、LSTM、およびGRUの3つのRNNでそれぞれモデルを構築し、文章の生成結果を比較します。"]},{"cell_type":"markdown","metadata":{"id":"BvsA4_jx1K3I"},"source":["## テキストデータの読み込み\n","Google ドライブからテキストデータを読み込みます。  \n","このノートブックと同じフォルダに、青空文庫の「銀河鉄道の夜」のテキストデータ\"gingatetsudono_yoru.txt\"がありますので、パスを指定して読み込みます。"]},{"cell_type":"code","metadata":{"id":"Dkf6xcck1wEq","cellView":"both","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628682589481,"user_tz":-540,"elapsed":908,"user":{"displayName":"石田竜宇","photoUrl":"","userId":"14178947605871169828"}},"outputId":"f01931a7-6f65-492d-c8cc-d958c20a687b"},"source":["from google.colab import drive\n","\n","drive.mount('/content/drive/')\n","nov_dir = 'Udemy_activity/ai_master_course/Section_8/'  # このフォルダへのパス\n","nov_path = '/content/drive/My Drive/04_Google Colaboratory/191211_AI Perfect Master (Colab Notebooks)/ai_master_course/Section_8（RNN）/gingatetsudono_yoru.txt'\n","\n","# ファイルを読み込む\n","with open(nov_path, 'r') as f:\n","  nov_text = f.read()\n","  print(nov_text[:1000])  # 最初の1000文字のみ表示"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n","「ではみなさんは、そういうふうに川だと云《い》われたり、乳の流れたあとだと云われたりしていたこのぼんやりと白いものがほんとうは何かご承知ですか。」先生は、黒板に吊《つる》した大きな黒い星座の図の、上から下へ白くけぶった銀河帯のようなところを指《さ》しながら、みんなに問《とい》をかけました。\n","　カムパネルラが手をあげました。それから四五人手をあげました。ジョバンニも手をあげようとして、急いでそのままやめました。たしかにあれがみんな星だと、いつか雑誌で読んだのでしたが、このごろはジョバンニはまるで毎日教室でもねむく、本を読むひまも読む本もないので、なんだかどんなこともよくわからないという気持ちがするのでした。\n","　ところが先生は早くもそれを見附《みつ》けたのでした。\n","「ジョバンニさん。あなたはわかっているのでしょう。」\n","　ジョバンニは勢《いきおい》よく立ちあがりましたが、立って見るともうはっきりとそれを答えることができないのでした。ザネリが前の席からふりかえって、ジョバンニを見てくすっとわらいました。ジョバンニはもうどぎまぎしてまっ赤になってしまいました。先生がまた云いました。\n","「大きな望遠鏡で銀河をよっく調べると銀河は大体何でしょう。」\n","　やっぱり星だとジョバンニは思いましたがこんどもすぐに答えることができませんでした。\n","　先生はしばらく困ったようすでしたが、眼《め》をカムパネルラの方へ向けて、\n","「ではカムパネルラさん。」と名指しました。するとあんなに元気に手をあげたカムパネルラが、やはりもじもじ立ち上ったままやはり答えができませんでした。\n","　先生は意外なようにしばらくじっとカムパネルラを見ていましたが、急いで「では。よし。」と云いながら、自分で星図を指《さ》しました。\n","「このぼんやりと白い銀河を大きないい望遠鏡で見ますと、もうたくさんの小さな星に見えるのです。ジョバンニさんそうでしょう。」\n","　ジョバンニはまっ赤になってうなずきました。けれどもいつかジョバンニの眼のなかには涙《なみだ》がいっぱいになりました。そうだ僕《ぼく》は知っていたのだ、勿論《もちろん》カムパネルラも知っている、それはいつかカムパネルラのお父さんの博士のうちでカムパネルラといっしょに読んだ雑誌のなかにあったのだ。それどこでなくカムパネルラは、その雑誌を読むと、すぐお父さんの書斎《しょさい》から巨《お\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"9C-l7uLVz7Ey"},"source":["## 正規表現による前処理\n","正規表現を使って、ルビなどを除去します。"]},{"cell_type":"code","metadata":{"id":"4OPrUpQyz7Ez","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628682600039,"user_tz":-540,"elapsed":1422,"user":{"displayName":"石田竜宇","photoUrl":"","userId":"14178947605871169828"}},"outputId":"6f73ec1d-7ca4-4820-f19b-24d68fd13d8b"},"source":["import re  # 正規表現に必要なライブラリ\n","\n","text = re.sub(\"《[^》]+》\", \"\", nov_text) # ルビの削除\n","text = re.sub(\"［[^］]+］\", \"\", text) # 読みの注意の削除\n","text = re.sub(\"[｜ 　]\", \"\", text) # | と全角半角スペースの削除\n","print(\"文字数\", len(text))  # len() で文字列の文字数も取得可能"],"execution_count":6,"outputs":[{"output_type":"stream","text":["文字数 38753\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"YY7sZvcIz7E2"},"source":["## 各設定\n","RNNの各設定です。"]},{"cell_type":"code","metadata":{"id":"aJ5ZYj61z7E3","executionInfo":{"status":"ok","timestamp":1628682608579,"user_tz":-540,"elapsed":233,"user":{"displayName":"石田竜宇","photoUrl":"","userId":"14178947605871169828"}}},"source":["n_rnn = 10  # 時系列の数\n","batch_size = 128\n","epochs = 60\n","n_mid = 128  # 中間層のニューロン数"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IhyUEeiUz7E5"},"source":["## 文字のベクトル化\n","各文字をone-hot表現で表し、時系列の入力データおよび正解データを作成します。  \n","今回はRNNの最後の時刻の出力のみ利用するので、最後の出力に対応する正解のみ必要になります。"]},{"cell_type":"code","metadata":{"id":"dwPgvftBz7E6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628682613188,"user_tz":-540,"elapsed":656,"user":{"displayName":"石田竜宇","photoUrl":"","userId":"14178947605871169828"}},"outputId":"064078e9-352c-452d-bc90-fe2c322847b4"},"source":["import numpy as np\n","\n","# インデックスと文字で辞書を作成\n","chars = sorted(list(set(text)))  # setで文字の重複をなくし、各文字をリストに格納する\n","print(\"文字数（重複無し）\", len(chars))\n","char_indices = {}  # 文字がキーでインデックスが値\n","for i, char in enumerate(chars):\n","    char_indices[char] = i\n","indices_char = {}  # インデックスがキーで文字が値\n","for i, char in enumerate(chars):\n","    indices_char[i] = char\n"," \n","# 時系列データと、それから予測すべき文字を取り出します\n","time_chars = []\n","next_chars = []\n","for i in range(0, len(text) - n_rnn):\n","    time_chars.append(text[i: i + n_rnn])\n","    next_chars.append(text[i + n_rnn])\n"," \n","# 入力と正解をone-hot表現で表します\n","x = np.zeros((len(time_chars), n_rnn, len(chars)), dtype=np.bool)\n","t = np.zeros((len(time_chars), len(chars)), dtype=np.bool)\n","for i, t_cs in enumerate(time_chars):\n","    t[i, char_indices[next_chars[i]]] = 1  # 正解をone-hot表現で表す\n","    for j, char in enumerate(t_cs):\n","        x[i, j, char_indices[char]] = 1  # 入力をone-hot表現で表す\n","        \n","print(\"xの形状\", x.shape)\n","print(\"tの形状\", t.shape)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["文字数（重複無し） 1049\n","xの形状 (38743, 10, 1049)\n","tの形状 (38743, 1049)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Aw-anpEHz7E8"},"source":["## モデルの構築\n","SimpleRNN、LSTM、GRUの層を使ったモデルをそれぞれ構築します。"]},{"cell_type":"code","metadata":{"id":"U7rC0ASgz7E8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628682623911,"user_tz":-540,"elapsed":8213,"user":{"displayName":"石田竜宇","photoUrl":"","userId":"14178947605871169828"}},"outputId":"ccc32019-e7da-43db-96ef-be834165d67d"},"source":["from keras.models import Sequential\n","from keras.layers import Dense, SimpleRNN, LSTM, GRU\n","\n","# SimpleRNN\n","model_rnn = Sequential()\n","model_rnn.add(SimpleRNN(n_mid, input_shape=(n_rnn, len(chars))))\n","model_rnn.add(Dense(len(chars), activation=\"softmax\"))\n","model_rnn.compile(loss='categorical_crossentropy', optimizer=\"adam\")\n","print(model_rnn.summary())\n","\n","# LSTM\n","model_lstm = Sequential()\n","model_lstm.add(LSTM(n_mid, input_shape=(n_rnn, len(chars))))\n","model_lstm.add(Dense(len(chars), activation=\"softmax\"))\n","model_lstm.compile(loss='categorical_crossentropy', optimizer=\"adam\")\n","print(model_lstm.summary())\n","\n","# GRU\n","model_gru = Sequential()\n","model_gru.add(GRU(n_mid, input_shape=(n_rnn, len(chars))))\n","model_gru.add(Dense(len(chars), activation=\"softmax\"))\n","model_gru.compile(loss='categorical_crossentropy', optimizer=\"adam\")\n","print(model_gru.summary())"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","simple_rnn (SimpleRNN)       (None, 128)               150784    \n","_________________________________________________________________\n","dense (Dense)                (None, 1049)              135321    \n","=================================================================\n","Total params: 286,105\n","Trainable params: 286,105\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","lstm (LSTM)                  (None, 128)               603136    \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 1049)              135321    \n","=================================================================\n","Total params: 738,457\n","Trainable params: 738,457\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","Model: \"sequential_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","gru (GRU)                    (None, 128)               452736    \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 1049)              135321    \n","=================================================================\n","Total params: 588,057\n","Trainable params: 588,057\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"RJANWVEJz7E-"},"source":["## 文書生成用の関数\n","各エポックの終了後、文章を生成するための関数を記述します。  \n","LambdaCallbackを使って、エポック終了時に実行される関数を設定します。"]},{"cell_type":"code","metadata":{"id":"zN2yJcvmz7E_","executionInfo":{"status":"ok","timestamp":1628682633514,"user_tz":-540,"elapsed":376,"user":{"displayName":"石田竜宇","photoUrl":"","userId":"14178947605871169828"}}},"source":["from keras.callbacks import LambdaCallback\n"," \n","def on_epoch_end(epoch, logs):\n","    print(\"エポック: \", epoch)\n","\n","    beta = 5  # 確率分布を調整する定数\n","    prev_text = text[0:n_rnn]  # 入力に使う文字\n","    created_text = prev_text  # 生成されるテキスト\n","    \n","    print(\"シード: \", created_text)\n","\n","    for i in range(400):\n","        # 入力をone-hot表現に\n","        x_pred = np.zeros((1, n_rnn, len(chars)))\n","        for j, char in enumerate(prev_text):\n","            x_pred[0, j, char_indices[char]] = 1\n","        \n","        # 予測を行い、次の文字を得る\n","        y = model.predict(x_pred)\n","        p_power = y[0] ** beta  # 確率分布の調整\n","        next_index = np.random.choice(len(p_power), p=p_power/np.sum(p_power))        \n","        next_char = indices_char[next_index]\n","\n","        created_text += next_char\n","        prev_text = prev_text[1:] + next_char\n","\n","    print(created_text)\n","    print()\n","\n","# エポック終了後に実行される関数を設定\n","epock_end_callback= LambdaCallback(on_epoch_end=on_epoch_end)"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pvDaiwJEz7FB"},"source":["## 学習\n","構築したモデルを使って、学習を行います。  \n","fit( )メソッドをではコールバックの設定をし、エポック終了後に関数が呼ばれるようにします。  \n","学習には時間がかかりますので、編集→ノートブックの設定のハードウェアアクセラレーターでGPUを選択しましょう。"]},{"cell_type":"code","metadata":{"id":"Ygj38MhQz7FB","colab":{"base_uri":"https://localhost:8080/"},"outputId":"33dce8a8-e26e-44ff-d9c6-5eb2043334ae"},"source":["# シンプルなRNN\n","model = model_rnn\n","history_rnn = model_rnn.fit(x, t,\n","                    batch_size=batch_size,\n","                    epochs=epochs,\n","                    callbacks=[epock_end_callback])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/60\n","303/303 [==============================] - 23s 10ms/step - loss: 5.3109\n","エポック:  0\n","シード:  「ではみなさんは、そ\n","「ではみなさんは、そたたとたましたののの、したののいのののののいまのしのまのたののいのいた。うていた。いまのたののいのてのうまたたののかまのいうてた、、たたたらいのののう、のののたたのしたてっしたのまかのたたののうのしのののの、のうの。ののいのののしていのののった、まのたうの、ののしのの、のたのたうたまのたのいした。たのうのうの、ま、たのののいのいのうがのいののたたのののう、いのしのたいがしてのしらうていのまたたいのをいたのかののののううまた、うのうの、たはにのののていたのいたいのののいののいたいのっ。たのたいましたうしのいののしたまったたののいいいのかたいまいっうののしののたのののうのうののて、のかののてたたの、たののたのしのま、いていうたいにたな。ののののまって。のたいいのたたのたうののののうののの、、し。のしたのたいののしののま、ののののして。いまたたが、のた。たののい、うのののかい、のたいののいたうか\n","\n","Epoch 2/60\n","303/303 [==============================] - 3s 11ms/step - loss: 4.6555\n","エポック:  1\n","シード:  「ではみなさんは、そ\n","「ではみなさんは、そのでした。\n","「あの、のはのにのした。\n","「のの、はの、ののにになてました。\n","「どは、のはのをのした。\n","「はした。\n","「ののはの、ののにのかのなのっていました。\n","「この、うにでのていていいした。\n","「あのはのなのなになのようになした。\n","「した。\n","「のは、ののののはのにのでのらのにのにのした。」\n","「した。」\n","「はのでの、をにっていました。\n","「のがうにないました。\n","「のの、にはのはのにのした。\n","「ののはののののにに、ました。\n","「\n","のののはのかにないてした。\n","「そのでした。\n","「ののうのでした。\n","「あの、のはのはは、いのした。」\n","「ョはンニは、ってのはに、っていた。」\n","「はは、いののはに、なました。\n","「ののはのはにないてした。\n","「ののはははっていたのでした。\n","「ののうのののははいました。\n","「あの、のなのはになっていました。\n","「あの、のはっていてした。\n","「ののはにのって、ました。\n","「ました。\n","「した。\n","「の\n","\n","Epoch 3/60\n","303/303 [==============================] - 3s 10ms/step - loss: 4.0761\n","エポック:  2\n","シード:  「ではみなさんは、そ\n","「ではみなさんは、そのです。」\n","「あました。\n","「あの、うにはいました。\n","「あいました。\n","「あん、いうのです。」\n","「あの、うのでした。\n","「あいました。\n","「ああいました。\n","「あう、そのでは、そうに、いました。\n","「あるとうに、いました。\n","「あいました。\n","「あのとうに、そのです。」\n","「あら、そのでが、ました。\n","「あうました。\n","「あの、うになっていました。\n","「あいました。\n","「あいました。\n","「いました。\n","「あるとうに、っていました。\n","「あいました。\n","「あるとうのです。」\n","「あのように、っていました。\n","「もういとした。\n","「あいました。\n","「あるとうに、っていました。\n","「あいました。\n","「あが、そのなのでした。\n","「あれていました。\n","「あました。\n","「あうした。\n","「あの、うに、っていました。\n","「あいました。\n","「あいました。\n","「あいました。\n","「あのでした。\n","「あんないないました。\n","「あいました。\n","「あいました。\n","「あいました。\n","「あい\n","\n","Epoch 4/60\n","303/303 [==============================] - 3s 10ms/step - loss: 3.7361\n","エポック:  3\n","シード:  「ではみなさんは、そ\n","「ではみなさんは、そのです。」\n","「あいました。\n","「あんないました。\n","「あんないました。\n","「あんないました。\n","「あから、そのです。」\n","「あったり、そのです。」\n","「あいました。\n","「ああ、その子を見ていました。\n","「あは、そのはは、そのです。」\n","「あの、その中に、そのように、いました。\n","「ああ、その子の方を見ていました。\n","「ああ、そのです。」\n","「あは、その中を見ていました。\n","「ああ、その中を、まった。\n","「ああ、その中のです。」\n","「あんないました。\n","「あいました。\n","「あからいました。\n","「ああ、その子のです。」\n","「ある、その中のように、そのです。」\n","「あは、その子のです。」\n","「あん、そのなが、、そのです。」\n","「あは、その中は、そのです。」\n","「あも、そのはは、そのです。」\n","「あると、そのです。」\n","「あは、その中は、そのなを、ました。\n","「ああ、その子の、はんないました。\n","「ああ、その方は、いるのでした。\n","「あから、そのでした\n","\n","Epoch 5/60\n","303/303 [==============================] - 3s 10ms/step - loss: 3.4758\n","エポック:  4\n","シード:  「ではみなさんは、そ\n","「ではみなさんは、その中にはいるとうになっているのです。」\n","「あいました。\n","「ああ、その中には、いました。\n","「ああ、そうに、なんだんですっていました。\n","「ああ、その中には、いました。\n","「ああ、その子のです。」\n","「あが、その中にはいるとうになっていました。\n","「ああ、その中には、あっていました。\n","「ああ、その子の中に、あっていました。\n","「ああ、あのおをさんないろのです。」\n","「あんないとした。\n","「ああ、その中には、いました。\n","「ああ、そうに、まったのです。\n","「ああ、そうにもうしているのでした。\n","「ああ、そのです。そのです。」\n","「ああ、その方のですか。」\n","「ああ、そうにもうっているのです。」\n","「あが、その中には、いました。\n","「ああ、その中には、いました。\n","「ああ、その中には、いました。\n","「ああ、そうにから、そのですから、もうにないろのでした。\n","「ああ、そうに、そのですか。」\n","「ああ、そのです。」\n","「あの、そのでした。\n","\n","Epoch 6/60\n","303/303 [==============================] - 3s 11ms/step - loss: 3.2987\n","エポック:  5\n","シード:  「ではみなさんは、そ\n","「ではみなさんは、そのです。そのです。そのです。\n","「ああ、そのです。\n","「ああ、そのです。\n","「ああ、そのです。」\n","「ああ、そのです。\n","「ああ、そのです。\n","「あありました。\n","「ああ、その中には、あっていました。\n","「ああした。\n","「ああ、ました。\n","「ああ、そのです。」\n","「ああ、その中に、あっているのでした。\n","「ああした。\n","「ああ、その中に、そのです。\n","「あありました。\n","「ああ、そのです。」\n","「ああ、その中には、あっていった。\n","「あああり、そのでした。\n","「ああした。\n","「ああ、そのです。」\n","「ああ、その子のです。\n","「ああ、その中には、あっていました。\n","「ああ、その中には、あっていました。\n","「ああ、そのです。」\n","「ああ、そのです。\n","「ああ、そのです。\n","「ああ、その中に、そのです。そのです。そのです。\n","「あありました。\n","「ああ、その中には、あっていました。\n","「ああ、その子のです。」\n","「ああした。\n","「ああ、そのです。\n","「ああ、\n","\n","Epoch 7/60\n","303/303 [==============================] - 3s 11ms/step - loss: 3.1058\n","エポック:  6\n","シード:  「ではみなさんは、そ\n","「ではみなさんは、その中にはなって、まったのです。」\n","「ああ、その子は、あっていました。\n","「ああ、その中に、それは、あっていました。\n","「ああ、その中には、きっとりまったりました。\n","「ああ、その中には、つっているのです。そのでは、なっともうかったり、あっていました。\n","「ああ、その中になって行って、ました。\n","「ああ、その中になって、まったりした。\n","「ああ、その中には、ついているだ。」\n","「ああ、そのは、そのといろのとになって、まったりのでした。\n","「ああ、そのははなんといろうから、あのような。」\n","「ああ、そのははなんだんです。」\n","「ああ、そのは、なっと、おっとりないとしました。\n","「ああ、その中には、きっといっていました。\n","「ああ、その中には、ついました。\n","「ああ、その中には、まったり、するとなって、まったりしました。\n","「ああ、その中には、あっていました。\n","「ああ、その中になっていました。\n","「ああ、その中には、きっとり\n","\n","Epoch 8/60\n","303/303 [==============================] - 3s 10ms/step - loss: 2.9662\n","エポック:  7\n","シード:  「ではみなさんは、そ\n","「ではみなさんは、そのです。」\n","「ああ、そのです。」\n","「ああ、その中には、このでした。\n","「ああ、そのです。。」\n","「ああ、その子は、こっと、この中に、まったのですか。」\n","「ああ、その中には、ぼくやりなって、まったのです。」\n","「ああ、その中には、こといろうになって、まった。\n","「ああ、そうだ。」\n","「ああ、そのは、その中には、あるとうう。」\n","「ああ、そのです。」\n","「ああ、その中には、このでした。\n","「ああ、そのです。」\n","「ああ、そのは、そのです。そのです。」\n","「ああ、ました。\n","「ああ、そのは、そのでした。\n","「ああ、そのは、そのでした。\n","「ああ、そのです。」\n","「ああ、そのは、その人は、もうだんだんだんだんだんだんだんだんだんだんだんだんだんだんだんだんだんだんだんだんだんだんだんだんだんだんだんだんだんだんだんだんです。」\n","「ああ、そのです。」\n","「ああ、そのは、そのです。」\n","「ああ、そうなんだ。」\n","「ああ、その子の中に、\n","\n","Epoch 9/60\n","303/303 [==============================] - 3s 11ms/step - loss: 2.8547\n","エポック:  8\n","シード:  「ではみなさんは、そ\n","「ではみなさんは、そうになって、そうから、もうなって、それから、ぼくやりのでした。\n","「ああたり、す。」\n","「ああ、どこらないうように、もうなんです。」\n","「ああ、その中をはました。\n","「ああたりさん。」\n","「ああ、そうなって、おってくなって、まったのです。\n","「ああたり、す。」\n","「ああ、その人は、こっちを見ているのでした。\n","「ああ、その中にはなって来るのでした。\n","「ああ、その中に、そっちを見ているのです。」\n","「ああたり、そのです。\n","「ああ、もう、どうか。」\n","「ああ、そのです。\n","「ああたくさん。」\n","「ああ、そうなっと、こっちに見ているのでした。\n","「ああ、その中にはちらって見ました。\n","「ああ、その中にはなって来るのでした。\n","「ああ、そのお父さんは、たくかり、どんなんです。」\n","「ああたり、どうか。」\n","「ああ、どこらないうでした。\n","「ああ、その中にはなって来るのでした。\n","「ああ、そのです。\n","「ああたり、すぐらんなんだ。」\n","「あ\n","\n","Epoch 10/60\n","303/303 [==============================] - 3s 11ms/step - loss: 2.7211\n","エポック:  9\n","シード:  「ではみなさんは、そ\n","「ではみなさんは、そうにうにならいました。\n","「ああ、そうに、そうどうしてもいるのです。そのでもなら、それをもなくり、それを見ました。\n","「ああ、そうに、あるといろの方の方を見ているのでした。\n","「ああ、その方へ見ているでした。\n","「ああ、その中に、それを見ているのでした。\n","「ああ、そのは、そうちを見ていました。\n","「ああ、その人たちを見え、その人たちになるようになって、まったのです。\n","「ああたりその中に、おっているのでした。\n","「ああ、そうに、あっているのでした。\n","「ああ、そのは、その人の川のように見ているのでした。\n","「ああ、そうに、そうちの上にはまるでしているのでした。\n","「ああ、そうに、そんなりに、ありました。\n","「ああ、そうに、そうとうにしているのでした。\n","「ああ、そうに、そうとうになりの方を見ていました。\n","「ああ、そうに、そうとうにしているのでした。\n","「ああ、そうに、そうとうしろがら、いるのでした。\n","「そうに、そっ\n","\n","Epoch 11/60\n","303/303 [==============================] - 3s 11ms/step - loss: 2.6264\n","エポック:  10\n","シード:  「ではみなさんは、そ\n","「ではみなさんは、その人たちは、もうじろの人は、まったのです。その人は、こんだんだんなんながら、そのでもその方を見ているように、あるところを見えました。\n","「ああ、その中に、ぼくやりのようになって、それは、あるというのです。\n","「ああ、そうなって、このでした。\n","「ああ、そのです。」\n","「ああ、こんないまです。\n","「ああ、そうな、その中に、あって来るのでした。\n","「ああ、そのです。」\n","「ああ、そのは、あの人は、もうとこの人は、まったくさっきのように、あるところが、もうじろいろがらって、まったのです。\n","「ああ、そうな。」\n","「ああ、その中に、こっとをもって、まっていました。\n","「ああ、その人は、こんでもわって来るのでした。\n","「ああ、その中に、それを見ていました。\n","「ああ、そのです。」\n","「ああ、その中に、おっているときれていました。\n","「ああ、そのは、その中に見えるところが、その人を見て、ました。\n","「ああ、もうじろいろのようにない\n","\n","Epoch 12/60\n","303/303 [==============================] - 3s 10ms/step - loss: 2.5339\n","エポック:  11\n","シード:  「ではみなさんは、そ\n","「ではみなさんは、そうにうしくらって来ました。\n","「ああ、そうな。」\n","「ああ、こんなんです。」\n","「ああ、それどもそうに、あの人は、もうって、そうとうした。\n","「ああ、そうに、あるところになって、それにもうっているのでした。\n","「ああ、そのですか。」\n","「ああ、もうだんだんだんだんなんなり、すきからしているように思って、まったのですか。」\n","「ああ、そうにうですから。」\n","「ああ、それどもなたちが、どうとうしろの方を見えて、そのですから、まったり、するとそのをきました。\n","「ああ、そうなんですからしたったりですか。」\n","「ああ、そうなんです。」\n","「ああ、それどうです。」\n","「ああ、そうなって、白いついたくさんですよ。」\n","「ああ、そうなって、こっちを見ているように、あるところを見えました。\n","「ああ、そうに、あるとはうから、そのですか。」\n","「ああ、そうなんですからしているように、きっきの方を見ていているのです。\n","「ああ、そうなったり\n","\n","Epoch 13/60\n","303/303 [==============================] - 3s 11ms/step - loss: 2.4329\n","エポック:  12\n","シード:  「ではみなさんは、そ\n","「ではみなさんは、その人たちを見て、そのできから、それをもなって、まったように、ありました。\n","「ああ、そのは、もうこの人は、なっとの方を見えながらしてそれをもした。\n","「ああ、そのは、さんないうしろには、きっとりにいまった。\n","「あありません。」\n","「ああ、そのはきのように、きって行くのように、まったように、きれてもうってその方を見ました。\n","「ああ、その子の中にはいたのですからしたのですか。」\n","「ああ、そしは、ジョバンニは、あっとない。」\n","「ああ、それは、そうから、もうから、そのです。\n","「あありはその中にはなくらいていたような。」\n","「ああ、そうから、なくらからないようにしたように、きっとの方を見ているように、いいながら、それはもうにいったりは、うになから、いるのですから、そのではたのですか。」\n","「ああ、そうから、もういうになったのです。」\n","「ああ、それは、ジョバンニはまったりしました。そのときのように、きっとりの上\n","\n","Epoch 14/60\n","303/303 [==============================] - 3s 12ms/step - loss: 2.3601\n","エポック:  13\n","シード:  「ではみなさんは、そ\n","「ではみなさんは、その人は、どこかないろの。」\n","「ああ、こんなんだんなにいってさん。」\n","「ああ、おっちを見えるように思ったのです。」\n","「いっぱいに行っていました。\n","「その中にはなってしているのでした。\n","「ああ、そのは、そのお父さんは、たくかったちのよ。」\n","「ああ、どんなんだ。」\n","「ああ、そのお父さんはぼくの方を見ているのでした。\n","「ああ、お母さんのお父さんのお父さんのお父さんがおるにはなんだ。」\n","「いうしろう。」\n","「ああ、どこかどもどこして、あんだんだんなんなんな。そのはきのようになんやりなくのでしたのです。その中にはなっとしているのでした。\n","「ああ、お父さんのお父さんはきないと思いながら、そっきの方へ行くらした。それは、ぼくやりなんだろう。」\n","「ああ、どこかなはうのですか。」\n","「ああ、お父さんはいるのですか。」\n","「ああ、お父さんのお父さんは、ないろのはないような気がしました。\n","「ああ、おったくなって、この人\n","\n","Epoch 15/60\n","303/303 [==============================] - 3s 10ms/step - loss: 2.2714\n","エポック:  14\n","シード:  「ではみなさんは、そ\n","「ではみなさんは、その白いにないよ。」\n","「ああ、どこから、ものですか。」\n","「ああ、その人の中になったりました。\n","「ああ、その鳥の中に、一つのつくして、ました。\n","「ああ、そのはきなさんは一ぺんに、白く時計をつって、\n","「あああたり、すぐうころのはもうとしたんだんだんだんだんだんなにながら、いるでもな。」\n","「ああ、それから、うころうしたのです。」\n","「ああ、そのお父さんのように、あるりはいのないました。\n","「ああ、そのは、さんだか、どうだろう。」\n","「ああ、それから、うころこへ行って、すぐにはあのました。\n","「ああ、その人は、二人は、二人に見えました。\n","「ああ、その人は、こんですかになるんだ。」ジョバンニはましました。\n","「ああ、その人たちは、もうこんなはもときっとり、そのでした。\n","「ああたちは、ぼくのように、あるりがらってかるよ。」\n","「ああ、どこらだいうないにはもうそのですから、いました。\n","「ああ、そのですか。」\n","「ああ、\n","\n","Epoch 16/60\n","303/303 [==============================] - 3s 10ms/step - loss: 2.1903\n","エポック:  15\n","シード:  「ではみなさんは、そ\n","「ではみなさんは、そうのような音がたちがられどもなんだ。その人は、ぼんやりしているのでした。\n","「ああ、そのです。」\n","「ああ、そのですか。」\n","「ぼんだ。そうかだ。ぼくはもうつからいようになって、まったのですか。」\n","「ああ、そうなって、このです。」\n","「ああ、そのは、ぼくやりしてかるように、きっとの方を通りました。\n","「ああ、ぼんは、ぼくはおっていました。\n","「ああ、そのです。」\n","「ああ、そのは、あらなり、どうどうして、そうにうすから、二人は、きまったり、おりだとうのような。」\n","「ああ、どこらだいうなり、すぐらのように、まるですかになって、ジョバンニはました。\n","「ああ、そのです。」\n","「ああ、その中にはなっとしているとした。そのではいないでしょう。」\n","「あありました。\n","「この人は、なんだんだんなんなりのでい。」\n","「ああ、そのですか。」\n","「ああ、そうだ。」\n","「いました。\n","「いうしろう。」\n","「ああ、そうなって、こっちの方へ行\n","\n","Epoch 17/60\n","303/303 [==============================] - 4s 12ms/step - loss: 2.1156\n","エポック:  16\n","シード:  「ではみなさんは、そ\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6XrSD7_Wt7FF"},"source":["# LSTM\n","model = model_lstm\n","history_lstm = model_lstm.fit(x, t,\n","                    batch_size=batch_size,\n","                    epochs=epochs,\n","                    callbacks=[epock_end_callback])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mBD6heuXuC4k"},"source":["# GRU\n","model = model_gru\n","history_gru = model_gru.fit(x, t,\n","                    batch_size=batch_size,\n","                    epochs=epochs,\n","                    callbacks=[epock_end_callback])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OcrTcdKlz7FD"},"source":["今回のケースでは、RNN < LSTM < GRUの順で文章が自然に見えます。  \n","SimpleRNNでは昔の文脈を利用するのが難しいのですが、GRUではある程度利用できているようです。  \n","興味のある方は、様々な条件をトライし、より自然な文章の生成にトライしてみましょう。  "]},{"cell_type":"markdown","metadata":{"id":"LoPdwHq2z7FE"},"source":["## 学習の推移\n","誤差の推移を確認します。"]},{"cell_type":"code","metadata":{"id":"hajdXxYXz7FE"},"source":["import matplotlib.pyplot as plt\n","\n","loss_rnn = history_rnn.history['loss']\n","loss_lstm = history_lstm.history['loss']\n","loss_gru = history_gru.history['loss']\n","\n","plt.plot(np.arange(len(loss_rnn)), loss_rnn, label=\"RNN\")\n","plt.plot(np.arange(len(loss_lstm)), loss_lstm, label=\"LSTM\")\n","plt.plot(np.arange(len(loss_gru)), loss_gru, label=\"GRU\")\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"p3XwrsSuz7FG"},"source":["誤差はまだ収束していないので、さらにエポック数を重ねることにより結果は改善しそうです。  \n","今回は文章の生成を行いましたが、同様にしてRNNを市場予測や自動作曲などに応用することも可能です。"]},{"cell_type":"markdown","metadata":{"id":"_oXiPDbCw6-2"},"source":["## さらに自然な文章の生成のために\n","さらに自然な文章生成が可能なモデルを作るために、例えば以下のようなアプローチが有効かもしれません。\n","\n","* **入力を単語ベクトルにする**  \n","入力をone-hot表現ではなくword2vecなどの技術により作る単語ベクトルにします。  \n","これにより、入力の次元数が抑えられるだけではなく、単語同士の関係性がモデルの訓練前にすでに存在することになります。    \n","word2vecについては、Udemyコース「自然言語処理とチャットボット: AIによる文章生成と会話エンジン開発」で詳しく解説しています。\n","\n","* **コーパスをさらに大きくする**  \n","一般的に、コーパスが大きいほどモデルの汎用性は高まります。  \n","しかしながら、学習かかる時間が長くなるのが問題です。  \n","\n","* **最新のアルゴリズムを採用する**  \n","自然言語処理の分野では日々新しい技術が生まれ、論文などで発表されています。  \n","興味のある方は、そのような技術をモデルに取り入れてみましょう。"]}]}